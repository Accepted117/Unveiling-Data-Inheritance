20:43:33 <INFO> Started REINVENT 4.4.22 (C) AstraZeneca 2017, 2023 on 2024-08-25
20:43:33 <INFO> Command line: /home/zhouhao/anaconda3/envs/reinvent4/bin/reinvent -l transfer_learning.log transfer_learning.toml
20:43:33 <INFO> User zhouhao on host dpai
20:43:33 <INFO> Python version 3.10.14
20:43:33 <INFO> PyTorch version 2.2.1+cu121, git 6c8c5ad5eaf47a62fafbb4a2747198cbffbf1ff0
20:43:33 <INFO> PyTorch compiled with CUDA version 12.1
20:43:33 <INFO> RDKit version 2023.09.5
20:43:33 <INFO> Platform Linux-5.15.0-119-generic-x86_64-with-glibc2.35
20:43:34 <INFO> CUDA driver version 550.76
20:43:34 <INFO> Number of PyTorch CUDA devices 1
20:43:34 <INFO> Using CPU x86_64
20:43:34 <INFO> Writing TensorBoard summary to /home/zhouhao/zzl/undel_drug/tb_TL
20:43:34 <INFO> Writing JSON config file to /home/zhouhao/zzl/undel_drug/json_transfer_learning.json
20:43:34 <INFO> Starting Transfer Learning
20:43:35 <ERRO> /home/zhouhao/REINVENT4/priors/mol2mol_scaffold_generic.prior has invalid hash:
{ 'comments': [],
  'creation_date': 0,
  'date_format': 'UNIX epoch',
  'hash_id': '2e9b50a81011b9dcae60e555a73a6144',
  'hash_id_format': 'xxhash.xxh3_128_hex 3.4.1',
  'model_id': 'dbe73d69456f42f990b955233dc7f514',
  'model_id_format': 'uuid.uuid4 3.10.12',
  'origina_data_source': 'ChEMBL 28',
  'updates': []}
20:43:36 <INFO> Number of network parameters: 17,462,400
20:43:36 <INFO> Network architecture:
EncoderDecoder(
  (encoder): Encoder(
    (layers): ModuleList(
      (0-5): 6 x EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0-3): 4 x Linear(in_features=256, out_features=256, bias=True)
          )
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (sublayer): ModuleList(
          (0-1): 2 x SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (norm): LayerNorm()
  )
  (decoder): Decoder(
    (layers): ModuleList(
      (0-5): 6 x DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0-3): 4 x Linear(in_features=256, out_features=256, bias=True)
          )
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0-3): 4 x Linear(in_features=256, out_features=256, bias=True)
          )
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (sublayer): ModuleList(
          (0-2): 3 x SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (norm): LayerNorm()
  )
  (src_embed): Sequential(
    (0): Embeddings(
      (lut): Embedding(128, 256)
    )
    (1): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (tgt_embed): Sequential(
    (0): Embeddings(
      (lut): Embedding(128, 256)
    )
    (1): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (generator): Generator(
    (proj): Linear(in_features=256, out_features=128, bias=True)
  )
)
20:43:36 <INFO> Using generator Mol2Mol
20:43:39 <INFO> Read 1050 input SMILES from /home/zhouhao/zzl/undel_drug/train.smi
20:43:40 <INFO> Read 266 validation SMILES from /home/zhouhao/zzl/undel_drug/validation.smi
20:43:40 <WARN> randomize_smiles is set to be True by user. But the model was trained using canonical SMILESwhere randomize_smiles might undermine the performance (this needs more investigation), but randomize_smiles is reset to be False for now.
20:43:42 <INFO> Creating Tanimoto pairs with 1 processes...
20:43:44 <INFO> Tanimoto pairs created
20:43:44 <INFO> Indexing training pairs...
20:43:44 <INFO> Number of training pairs: 1357
20:43:44 <INFO> Indexing validation pairs...
20:43:44 <INFO> Number of validation pairs: 310
00:23:23 <INFO> Best validation loss (2.756) was at epoch 16
00:23:23 <INFO> Peak main memory usage: 56790.312 MiB
00:23:23 <INFO> Finished REINVENT on 2024-08-26
