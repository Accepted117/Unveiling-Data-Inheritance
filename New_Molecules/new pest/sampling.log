22:32:08 <INFO> Started REINVENT 4.4.22 (C) AstraZeneca 2017, 2023 on 2024-10-30
22:32:08 <INFO> Command line: /home/zi/anaconda3/envs/reinvent4/bin/reinvent -l sampling.log New_pest_1.toml
22:32:08 <INFO> User zi on host LAPTOP-F8894L1H
22:32:08 <INFO> Python version 3.11.9
22:32:08 <INFO> PyTorch version 2.2.1+cu121, git 6c8c5ad5eaf47a62fafbb4a2747198cbffbf1ff0
22:32:08 <INFO> PyTorch compiled with CUDA version 12.1
22:32:08 <INFO> RDKit version 2023.09.5
22:32:08 <INFO> Platform Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
22:32:10 <INFO> Number of PyTorch CUDA devices 1
22:32:10 <INFO> Using CPU x86_64
22:32:10 <INFO> Writing JSON config file to /home/zi/zhuziling/new pest/_sampling.json
22:32:10 <INFO> Starting Sampling
22:32:10 <INFO> /home/zi/zhuziling/new pest/TL_reinvent.model.26.chkpt has valid hash:
{ 'comments': ['TL'],
  'creation_date': 0,
  'date_format': 'UNIX epoch',
  'hash_id': 'c66b91c7127ebfa94cf500bdf0805511',
  'hash_id_format': 'xxhash.xxh3_128_hex 3.4.1',
  'model_id': 'dbe73d69456f42f990b955233dc7f514',
  'model_id_format': 'uuid.uuid4 3.10.12',
  'origina_data_source': 'ChEMBL 28',
  'updates': [1724389009.9126844]}
22:32:10 <INFO> Number of network parameters: 17,462,400
22:32:10 <INFO> Network architecture:
EncoderDecoder(
  (encoder): Encoder(
    (layers): ModuleList(
      (0-5): 6 x EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0-3): 4 x Linear(in_features=256, out_features=256, bias=True)
          )
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (sublayer): ModuleList(
          (0-1): 2 x SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (norm): LayerNorm()
  )
  (decoder): Decoder(
    (layers): ModuleList(
      (0-5): 6 x DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0-3): 4 x Linear(in_features=256, out_features=256, bias=True)
          )
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0-3): 4 x Linear(in_features=256, out_features=256, bias=True)
          )
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (sublayer): ModuleList(
          (0-2): 3 x SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (norm): LayerNorm()
  )
  (src_embed): Sequential(
    (0): Embeddings(
      (lut): Embedding(128, 256)
    )
    (1): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (tgt_embed): Sequential(
    (0): Embeddings(
      (lut): Embedding(128, 256)
    )
    (1): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (generator): Generator(
    (proj): Linear(in_features=256, out_features=128, bias=True)
  )
)
22:32:10 <INFO> Using generator Mol2Mol
22:32:10 <INFO> Writing sampled SMILES to CSV file new_pest_1.csv
22:32:10 <WARN> randomize_smiles is set to be True by user. But the model was trained using canonical SMILESwhere randomize_smiles might undermine the performance (this needs more investigation), but randomize_smiles is reset to be False for now.
