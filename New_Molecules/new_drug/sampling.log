15:43:00 <INFO> Started REINVENT 4.4.22 (C) AstraZeneca 2017, 2023 on 2024-09-04
15:43:00 <INFO> Command line: /home/zi/anaconda3/envs/reinvent4/bin/reinvent -l sampling.log New_drug.toml
15:43:00 <INFO> User zi on host LAPTOP-F8894L1H
15:43:00 <INFO> Python version 3.11.9
15:43:00 <INFO> PyTorch version 2.2.1+cu121, git 6c8c5ad5eaf47a62fafbb4a2747198cbffbf1ff0
15:43:00 <INFO> PyTorch compiled with CUDA version 12.1
15:43:00 <INFO> RDKit version 2023.09.5
15:43:00 <INFO> Platform Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31
15:43:00 <INFO> Number of PyTorch CUDA devices 1
15:43:00 <INFO> Using CUDA device:0 NVIDIA GeForce RTX 4060 Laptop GPU
15:43:01 <INFO> GPU memory: 7113 MiB free, 8187 MiB total
15:43:01 <INFO> Writing JSON config file to /home/zi/zhuziling/new_drug/_sampling.json
15:43:01 <INFO> Starting Sampling
15:43:01 <INFO> /home/zi/zhuziling/new_drug/TL_reinvent.model.chkpt has valid hash:
{ 'comments': ['TL'],
  'creation_date': 0,
  'date_format': 'UNIX epoch',
  'hash_id': '1e340fea4cf314a6c31bd33fa58c9427',
  'hash_id_format': 'xxhash.xxh3_128_hex 3.4.1',
  'model_id': 'dbe73d69456f42f990b955233dc7f514',
  'model_id_format': 'uuid.uuid4 3.10.12',
  'origina_data_source': 'ChEMBL 28',
  'updates': [1724396244.4348536]}
15:43:01 <INFO> Number of network parameters: 17,462,400
15:43:01 <INFO> Network architecture:
EncoderDecoder(
  (encoder): Encoder(
    (layers): ModuleList(
      (0-5): 6 x EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0-3): 4 x Linear(in_features=256, out_features=256, bias=True)
          )
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (sublayer): ModuleList(
          (0-1): 2 x SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (norm): LayerNorm()
  )
  (decoder): Decoder(
    (layers): ModuleList(
      (0-5): 6 x DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0-3): 4 x Linear(in_features=256, out_features=256, bias=True)
          )
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linears): ModuleList(
            (0-3): 4 x Linear(in_features=256, out_features=256, bias=True)
          )
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (sublayer): ModuleList(
          (0-2): 3 x SublayerConnection(
            (norm): LayerNorm()
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (norm): LayerNorm()
  )
  (src_embed): Sequential(
    (0): Embeddings(
      (lut): Embedding(128, 256)
    )
    (1): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (tgt_embed): Sequential(
    (0): Embeddings(
      (lut): Embedding(128, 256)
    )
    (1): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (generator): Generator(
    (proj): Linear(in_features=256, out_features=128, bias=True)
  )
)
15:43:01 <INFO> Using generator Mol2Mol
15:43:01 <INFO> Writing sampled SMILES to CSV file new_drug.csv
15:43:01 <WARN> randomize_smiles is set to be True by user. But the model was trained using canonical SMILESwhere randomize_smiles might undermine the performance (this needs more investigation), but randomize_smiles is reset to be False for now.
15:43:01 <INFO> Sampling 2765 SMILES from model TL_reinvent.model.chkpt
15:45:35 <INFO> Peak main memory usage: 1262.730 MiB
15:45:35 <INFO> Finished REINVENT on 2024-09-04
